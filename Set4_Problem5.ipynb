{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the CIFAR10 dataset. It has the classes: ‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’, ‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’. The images in CIFAR-10 are of size 3x32x32, i.e. 3-channel color images of 32x32 pixels in size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training an image classifier\n",
    "----------------------------\n",
    "\n",
    "We will do the following steps in order:\n",
    "\n",
    "1. Load and normalizing the CIFAR10 training and test datasets using\n",
    "   ``torchvision``\n",
    "2. Define a Convolution Neural Network\n",
    "3. Define a loss function\n",
    "4. Train the network on the training data\n",
    "5. Test the network on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _num_flat_features(x):\n",
    "    size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "    num_features = 1\n",
    "    for s in size:\n",
    "        num_features *= s\n",
    "    return num_features\n",
    "\n",
    "\n",
    "class Net_C(nn.Module):\n",
    "    def __init__(self, M, p, N):\n",
    "        '''\n",
    "        M is the number of output channels, p is the convolution kernel size, \n",
    "        N is the max pooling kernel (ideally, it is a divisor of 33-p)\n",
    "        '''\n",
    "        super(Net_C, self).__init__()\n",
    "        # 3 input image channel, M output channels, pxpx3 square convolution; bias=True is default\n",
    "        self.conv1 = nn.Conv2d(3, M, p)\n",
    "        self.pool1 = nn.MaxPool2d(N)\n",
    "        self.fc1 = nn.Linear(M*((33-p)//N)**2, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = x.view(-1, self.num_flat_features(x)) # 32 * 32 * 3\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        return _num_flat_features(x)\n",
    "    \n",
    "\n",
    "class Net_B(nn.Module):\n",
    "    def __init__(self, M):\n",
    "        super(Net_B, self).__init__()\n",
    "        self.fc1 = nn.Linear(32 * 32 * 3, M)\n",
    "        self.fc2 = nn.Linear(M, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.num_flat_features(x)) # 32 * 32 * 3\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        return _num_flat_features(x)\n",
    "    \n",
    "\n",
    "class Net_A(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_A, self).__init__()\n",
    "        self.fc1 = nn.Linear(32 * 32 * 3, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.num_flat_features(x)) # 32 * 32 * 3\n",
    "        x = self.fc1(x) \n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        return _num_flat_features(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net(net, iter_trainloader, criterion, optimizer, epochs):\n",
    "    '''\n",
    "    Trains net and returns epoch-wise test loss\n",
    "    '''\n",
    "    epochs_train_loss = []\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        size = 0\n",
    "        for data in iter_trainloader: # AG: What is happening with this 0? \n",
    "            # get the inputs\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # sum statistics\n",
    "            size += 1\n",
    "            running_loss += loss.item()\n",
    "        # record loss    \n",
    "        epochs_train_loss.append(running_loss / size)\n",
    "    return epochs_train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_net(net, iter_testloader, criterion):\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        test_loss = 0.0\n",
    "        size = 0\n",
    "        for data in iter_testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            # Sum statistics\n",
    "            test_loss += loss.item()\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            size += 1\n",
    "    return test_loss / size, 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_accuracy(net, iter_testloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shared criterion for loss\n",
    "criterion_all = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making sure everything works...\n",
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net_A(\n",
      "  (fc1): Linear(in_features=3072, out_features=10, bias=True)\n",
      ")\n",
      "Net_B(\n",
      "  (fc1): Linear(in_features=3072, out_features=100, bias=True)\n",
      "  (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n",
      "Net_C(\n",
      "  (conv1): Conv2d(3, 100, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=19600, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create new NN's, print\n",
    "# netA = Net_A()\n",
    "# netB = Net_B(100)\n",
    "# netC = Net_C(100, 5, 2)\n",
    "print(netA)\n",
    "print(netB)\n",
    "print(netC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6351,  0.1992,  0.3159,  0.0204,  0.0754, -0.0463,  0.3125, -0.0823,\n",
      "         -0.0979, -0.3068],\n",
      "        [-0.0114,  0.1704,  0.0322, -0.2838,  0.1890, -0.3320,  0.0448, -0.2956,\n",
      "         -0.2089, -0.3648],\n",
      "        [ 0.1855,  0.4247,  0.1155, -0.0184, -0.1142, -0.2607,  0.3533, -0.4119,\n",
      "         -0.4639,  0.0784],\n",
      "        [-0.1018,  0.0246,  0.2024,  0.1081,  0.0579, -0.4817,  0.1117, -0.4587,\n",
      "         -0.0535,  0.0337]], grad_fn=<ThAddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "# This code made sure the NN's functioned correctly\n",
    "test_input = torch.randn(4, 3, 32, 32)\n",
    "for inet in [netB]:\n",
    "    out = inet(test_input)\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "working with Network A\n",
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netA = Net_A()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "netA(test_input);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare some optimizer for Net A\n",
    "resA=[]\n",
    "optimizerA = optim.SGD(netA.parameters(), lr=0.05, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\t 79.920, 76.249, 73.668, 71.825, 70.093, 69.397\n",
      "test:\t 76.059\n",
      "28% accuracy on 10000 test images.\n",
      "CPU times: user 3min 1s, sys: 8.29 s, total: 3min 10s\n",
      "Wall time: 1min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "resA.extend(train_net(netA, trainloader, criterion_all, optimizerA, 2))\n",
    "print('train:\\t', ', '.join(['%.3f' % i for i in resA]))\n",
    "loss, percent = test_net(netA, testloader, criterion_all)\n",
    "print('test:\\t', '%.3f' % loss )\n",
    "print('%d%% accuracy on 10000 test images.' % percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments:\n",
    "\n",
    "3 miuntes for 2 epochs => 15 minutes for 10 epochs\n",
    "\n",
    "If 3 hours alloted, number of random guesses allowed: 4*3 = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "working with Network B\n",
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "netB = Net_B(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "resB=[]\n",
    "optimizerB = optim.SGD(netB.parameters(), lr=0.01, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2983,  0.0816,  0.0660,  0.5593, -0.2924, -0.1701,  0.2301, -0.1060,\n",
       "         -0.0908,  0.0986],\n",
       "        [ 0.0435,  0.0322,  0.3295,  0.5355, -0.0843,  0.3337, -0.2070, -0.2223,\n",
       "         -0.1454,  0.0421],\n",
       "        [ 0.5170,  0.2725,  0.0528,  0.2867, -0.4661,  0.0534,  0.1140, -0.4153,\n",
       "          0.0380,  0.4172],\n",
       "        [ 0.1747,  0.3758,  0.3047, -0.3355, -0.0321, -0.2213, -0.1787,  0.0350,\n",
       "         -0.3845, -0.0765]], grad_fn=<ThAddmmBackward>)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netB(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "resB.extend(train_net(netB, trainloader, criterion_all, optimizerB, 2))\n",
    "print('train:\\t', ', '.join(['%.3f' % i for i in resB]))\n",
    "loss, percent = test_net(netB, testloader, criterion_all)\n",
    "print('test:\\t', '%.3f' % loss )\n",
    "print('%d%% accuracy on 10000 test images.' % percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test:\t 2.321\n",
      "8% accuracy on 10000 test images.\n"
     ]
    }
   ],
   "source": [
    "loss, percent = test_net(netB, testloader, criterion_all)\n",
    "print('test:\\t', '%.3f' % loss )\n",
    "print('%d%% accuracy on 10000 test images.' % percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nan, nan]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments:\n",
    "\n",
    "Why did B report nan for solutions with lr = 0.05 and p = .9? That's garbage.\n",
    "Tried .1. Still garbage. So can't learn too quickly.\n",
    "I tried it with lr=0.001, momentum=0.5 and I got answers but it never moved.\n",
    "\n",
    "Similar time for A and B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "working with Network C\n",
    "-----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "netC = Net_C(100, 5, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netC(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resC=[]\n",
    "optimizerC = optim.SGD(netC.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "resC.extend(train_net(netC, trainloader, criterion_all, optimizerC, 2))\n",
    "print('train:\\t', ', '.join(['%.3f' % i for i in resC]))\n",
    "loss, percent = test_net(netC, testloader, criterion_all)\n",
    "print('test:\\t', '%.3f' % loss )\n",
    "print('%d%% accuracy on 10000 test images.' % percent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
