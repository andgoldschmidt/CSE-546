{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from os.path import join\n",
    "\n",
    "# Assumes there is a .obj directory in the notebook folder\n",
    "def save_obj(obj, name, root=''):\n",
    "    with open(join(root, '.obj', name + '.pkl'), 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name, root=''):\n",
    "    with open(join(root, '.obj/', name + '.pkl'), 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the CIFAR10 dataset. It has the classes: ‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’, ‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’. The images in CIFAR-10 are of size 3x32x32, i.e. 3-channel color images of 32x32 pixels in size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12500"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training an image classifier\n",
    "----------------------------\n",
    "\n",
    "We will do the following steps in order:\n",
    "\n",
    "1. Load and normalizing the CIFAR10 training and test datasets using\n",
    "   ``torchvision``\n",
    "2. Define a Convolution Neural Network\n",
    "3. Define a loss function\n",
    "4. Train the network on the training data\n",
    "5. Test the network on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _num_flat_features(x):\n",
    "    size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "    num_features = 1\n",
    "    for s in size:\n",
    "        num_features *= s\n",
    "    return num_features\n",
    "\n",
    "\n",
    "class Net_C(nn.Module):\n",
    "    def __init__(self, M, p, N):\n",
    "        '''\n",
    "        M is the number of output channels, p is the convolution kernel size, \n",
    "        N is the max pooling kernel (ideally, it is a divisor of 33-p)\n",
    "        '''\n",
    "        super(Net_C, self).__init__()\n",
    "        # 3 input image channel, M output channels, pxpx3 square convolution; bias=True is default\n",
    "        self.conv1 = nn.Conv2d(3, M, p)\n",
    "        self.pool1 = nn.MaxPool2d(N)\n",
    "        self.fc1 = nn.Linear(M*((33-p)//N)**2, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = x.view(-1, self.num_flat_features(x)) # 32 * 32 * 3\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        return _num_flat_features(x)\n",
    "    \n",
    "\n",
    "class Net_B(nn.Module):\n",
    "    def __init__(self, M):\n",
    "        super(Net_B, self).__init__()\n",
    "        self.fc1 = nn.Linear(32 * 32 * 3, M)\n",
    "        self.fc2 = nn.Linear(M, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.num_flat_features(x)) # 32 * 32 * 3\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        return _num_flat_features(x)\n",
    "    \n",
    "\n",
    "class Net_A(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net_A, self).__init__()\n",
    "        self.fc1 = nn.Linear(32 * 32 * 3, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.num_flat_features(x)) # 32 * 32 * 3\n",
    "        x = self.fc1(x) \n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        return _num_flat_features(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net(net, iter_trainloader, criterion, optimizer, epochs, iter_testloader=None):\n",
    "    '''\n",
    "    Trains net and returns epoch-wise test loss\n",
    "    '''\n",
    "    epochs_train_loss = []\n",
    "    epochs_test_loss = []\n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        size = 0\n",
    "        for i, data in enumerate(iter_trainloader):\n",
    "            # get the inputs\n",
    "            inputs, labels = data\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 4000 == 3999:    # print every 4000 mini-batches\n",
    "                epochs_train_loss.append([epoch, i, running_loss / 4000])\n",
    "                running_loss = 0.0\n",
    "            size+=1\n",
    "        if iter_testloader:\n",
    "            test_loss,_ = test_net(netA, iter_testloader, criterion)\n",
    "            epochs_test_loss.append([epoch, size, test_loss])\n",
    "    return epochs_train_loss, epochs_test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_net(net, iter_testloader, criterion):\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        test_loss = 0.0\n",
    "        size = 0\n",
    "        for data in iter_testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            # Sum statistics\n",
    "            test_loss += loss.item()\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            size += 1\n",
    "    return test_loss / size, 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_accuracy(net, iter_testloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shared criterion for loss\n",
    "criterion_all = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making sure everything works...\n",
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create new NN's, print\n",
    "# # netA = Net_A()\n",
    "# # netB = Net_B(100)\n",
    "# # netC = Net_C(100, 5, 2)\n",
    "# print(netA)\n",
    "# print(netB)\n",
    "# print(netC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This code made sure the NN's functioned correctly\n",
    "test_input = torch.randn(4, 3, 32, 32)\n",
    "# for inet in [netB]:\n",
    "#     out = inet(test_input)\n",
    "#     print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "working with Network A\n",
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "netA = Net_A()\n",
    "resA=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare some optimizer for Net A\n",
    "optimizerA = optim.SGD(netA.parameters(), lr=0.0001, momentum=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16min 52s, sys: 51.9 s, total: 17min 44s\n",
      "Wall time: 9min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "resA_train, resA_test = train_net(netA, trainloader, criterion_all, optimizerA, 10, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\t 1.709, 1.652, 1.614, 1.605, 1.589, 1.595, 1.585, 1.563, 1.584, 1.567, 1.561, 1.572, 1.562, 1.581, 1.545, 1.556, 1.573, 1.546, 1.554, 1.544, 1.570, 1.548, 1.547, 1.561, 1.547, 1.544, 1.561, 1.533, 1.557, 1.556\n",
      "test:\t 1.900, 1.874, 1.865, 1.856, 1.850, 1.847, 1.843, 1.841, 1.839, 1.837\n",
      "test:\t 1.837\n",
      "38% accuracy on 10000 test images.\n"
     ]
    }
   ],
   "source": [
    "print('train:\\t', ', '.join(['%.3f' % i[2] for i in resA_train]))\n",
    "print('test:\\t', ', '.join(['%.3f' % i[2] for i in resA_test]))\n",
    "loss, percent = test_net(netA, testloader, criterion_all)\n",
    "print('test:\\t', '%.3f' % loss )\n",
    "print('%d%% accuracy on 10000 test images.' % percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, resA_train_0, resA_test_0 = load_obj('netA_20epoch_01_01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\t 2.038, 2.047, 2.053, 2.000, 2.073, 2.060, 1.996, 2.045, 2.080, 2.006, 2.037, 2.070, 2.001, 2.049, 2.059, 2.010, 2.044, 2.041, 2.000, 2.052, 2.047, 2.012, 2.029, 2.037, 1.998, 2.043, 2.046, 2.006, 2.041, 2.041\n",
      "test:\t 2.304, 2.279, 2.213, 2.132, 2.235, 2.123, 2.230, 2.245, 2.264, 2.228\n"
     ]
    }
   ],
   "source": [
    "print('train:\\t', ', '.join(['%.3f' % i[2] for i in resA_train_0]))\n",
    "print('test:\\t', ', '.join(['%.3f' % i[2] for i in resA_test_0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "resA_train_0 = np.array(resA_train_0)\n",
    "resA_test_0 = np.array(resA_test_0)\n",
    "resA_train = np.array(resA_train)\n",
    "resA_test = np.array(resA_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(resA_train_0[:,0]*12500 + resA_train_0[:,1], resA_train_0[:,2])\n",
    "prev = np.max(resA_train_0[:,0]*12500 + resA_train_0[:,1])\n",
    "plt.plot(prev + resA_train[:,0]*12500 + resA_train[:,1], resA_train[:,2])\n",
    "\n",
    "plt.scatter(resA_test_0[:,0]*12500, resA_test_0[:,2])\n",
    "prev_test = np.max((resA_test_0[:,0]+1)*12500)\n",
    "plt.scatter(prev_test + resA_test[:,0]*12500, resA_test[:,2])\n",
    "plt.xlabel('Step', fontsize=14)\n",
    "plt.ylabel('Loss', fontsize=14)\n",
    "plt.savefig('figs/p5_net_a.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_obj(name='netA_20epoch_0001_01', obj=[netA, resA_train, resA_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments:\n",
    "\n",
    "optimizerA = optim.SGD(netA.parameters(), lr=0.01, momentum=0.001)\n",
    "train:\t 2.201, 2.173, 2.162, 2.105, 2.129, 2.154, 2.112, 2.089, 2.101, 2.063, 2.094, 2.108, 2.061, 2.094, 2.080, 2.056, 2.071, 2.094, 2.037, 2.086, 2.079, 2.040, 2.065, 2.071, 2.021, 2.079, 2.063, 2.038, 2.043, 2.061\n",
    "test:\t 2.264, 2.223, 2.224, 2.263, 2.185, 2.196, 2.071, 2.293, 2.144, 2.279\n",
    "test:\t 2.279\n",
    "33% accuracy on 10000 test images.\n",
    "\n",
    "optimizerA = optim.SGD(netA.parameters(), lr=0.212, momentum=0.841)\n",
    "train:\t 175.991, 184.557, 185.608, 179.114, 184.203, 181.720, 178.520, 182.050, 186.387, 177.853, 184.370, 181.839, 173.380, 181.109, 182.531, 173.967, 177.103, 180.946, 173.629, 176.575, 180.742, 176.386, 176.638, 176.180, 176.842, 178.391, 181.318, 174.182, 177.223, 178.008\n",
    "test:\t 204.613, 188.560, 183.347, 186.685, 169.764, 200.698, 214.378, 189.993, 182.198, 188.476\n",
    "test:\t 188.476\n",
    "27% accuracy on 10000 test images.\n",
    "\n",
    "optimizerA = optim.SGD(netA.parameters(), lr=0.0831, momentum=0.945)\n",
    "train:\t 317.963, 262.889, 249.661, 228.552, 228.060, 223.247, 211.591, 216.781, 212.178, 205.501, 209.789, 208.317, 204.507, 206.900, 202.755, 196.580, 207.313, 204.035, 202.587, 202.032, 199.665, 199.495, 197.132, 206.281, 193.820, 207.734, 205.755, 199.321, 199.586, 201.819\n",
    "test:\t 272.428, 248.242, 233.457, 217.928, 218.635, 235.688, 224.741, 258.207, 239.864, 199.299\n",
    "test:\t 199.299\n",
    "29% accuracy on 10000 test images.\n",
    "\n",
    "lr = 0.05, p = .9\n",
    "train:\t 79.920, 76.249, 73.668, 71.825, 70.093, 69.397\n",
    "test:\t 76.059\n",
    "28% accuracy on 10000 test images.\n",
    "CPU times: user 3min 1s, sys: 8.29 s, total: 3min 10s\n",
    "Wall time: 1min 29s\n",
    "\n",
    "3 miuntes for 2 epochs => 15 minutes for 10 epochs\n",
    "\n",
    "If 3 hours alloted, number of random guesses allowed: 4*3 = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "working with Network B\n",
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "netB = Net_B(400)\n",
    "resB=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizerB = optim.SGD(netB.parameters(), lr=0.01, momentum=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4090, -0.0641,  0.0474, -0.1546,  0.2635,  0.1513,  0.3057, -0.3078,\n",
       "         -0.2881,  0.1360],\n",
       "        [-0.1789, -0.2995, -0.0761,  0.1897,  0.1121,  0.3744,  0.0944, -0.1846,\n",
       "         -0.1328, -0.1426],\n",
       "        [-0.0523, -0.0421, -0.3660,  0.0535, -0.1048,  0.1844, -0.0085, -0.0769,\n",
       "         -0.2485, -0.0773],\n",
       "        [-0.0363, -0.0456,  0.4121, -0.3898, -0.1444,  0.0878,  0.1636, -0.3042,\n",
       "         -0.1371,  0.0013]], grad_fn=<ThAddmmBackward>)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netB(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\t 2.036, 2.048\n",
      "test:\t 2.109\n",
      "38% accuracy on 10000 test images.\n",
      "CPU times: user 12min 4s, sys: 14.7 s, total: 12min 18s\n",
      "Wall time: 5min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "resB.extend(train_net(netB, trainloader, criterion_all, optimizerB, 2))\n",
    "print('train:\\t', ', '.join(['%.3f' % i for i in resB]))\n",
    "loss, percent = test_net(netB, testloader, criterion_all)\n",
    "print('test:\\t', '%.3f' % loss )\n",
    "print('%d%% accuracy on 10000 test images.' % percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments:\n",
    "\n",
    "m=100,lr=.01,p=[0.5,.7]\n",
    "train:\t 1.916, 1.851\n",
    "test:\t 1.988\n",
    "37% accuracy on 10000 test images.\n",
    "CPU times: user 4min 57s, sys: 11.4 s, total: 5min 8s\n",
    "Wall time: 2min 23s\n",
    "\n",
    "Why did B report nan for solutions with lr = 0.05 and p = .9? That's garbage.\n",
    "Tried .1. Still garbage. So can't learn too quickly.\n",
    "I tried  with lr = .01 and p=0.5 and it converged nicely.\n",
    "I tried it with lr=0.001, momentum=0.5 and I got answers but it never moved.\n",
    "\n",
    "Similar time for A and B: B was 2min 21s for lr = .01 and p=.5 and M = 100\n",
    "When M=400, this time went to: 5 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "working with Network C\n",
    "-----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "netC = Net_C(100, 6, 4)\n",
    "resC=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "netC(test_input);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizerC = optim.SGD(netC.parameters(), lr=0.01, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\t 1.392, 1.223, 1.173, 1.140, 1.109, 1.086, 1.062, 1.047\n",
      "test:\t 1.336\n",
      "60% accuracy on 10000 test images.\n",
      "CPU times: user 10min 45s, sys: 12.7 s, total: 10min 58s\n",
      "Wall time: 4min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "resC.extend(train_net(netC, trainloader, criterion_all, optimizerC, 2))\n",
    "print('train:\\t', ', '.join(['%.3f' % i for i in resC]))\n",
    "loss, percent = test_net(netC, testloader, criterion_all)\n",
    "print('test:\\t', '%.3f' % loss )\n",
    "print('%d%% accuracy on 10000 test images.' % percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_obj(name='netC_lr01_m5_100_6_4', obj=[netC, resC])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments:\n",
    "\n",
    "Training lr=0.01, p=.5 on Net_C(100, 5, 2) gives time of 6 minutes. Errors were at ~1.2 at 2 epochs. \n",
    "\n",
    "netC = Net_C(100, 6, 4)\n",
    "lr=0.01, momentum=0.5\n",
    "train:\t 1.392, 1.223\n",
    "test:\t 1.404\n",
    "55% accuracy on 10000 test images.\n",
    "CPU times: user 11min 35s, sys: 13.5 s, total: 11min 48s\n",
    "Wall time: 5min 5s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fun novelty functions \n",
    "------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_percent_error(net, iter_testloader):\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            c = (predicted == labels).squeeze()\n",
    "            for i in range(4):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "\n",
    "    for i in range(10):\n",
    "        print('Accuracy of %5s : %2d %%' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 64 %\n",
      "Accuracy of   car : 71 %\n",
      "Accuracy of  bird : 43 %\n",
      "Accuracy of   cat : 33 %\n",
      "Accuracy of  deer : 50 %\n",
      "Accuracy of   dog : 44 %\n",
      "Accuracy of  frog : 75 %\n",
      "Accuracy of horse : 63 %\n",
      "Accuracy of  ship : 75 %\n",
      "Accuracy of truck : 55 %\n"
     ]
    }
   ],
   "source": [
    "categorical_percent_error(netC, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 32 %\n",
      "Accuracy of   car : 50 %\n",
      "Accuracy of  bird : 17 %\n",
      "Accuracy of   cat : 25 %\n",
      "Accuracy of  deer : 17 %\n",
      "Accuracy of   dog : 29 %\n",
      "Accuracy of  frog : 32 %\n",
      "Accuracy of horse : 22 %\n",
      "Accuracy of  ship : 33 %\n",
      "Accuracy of truck : 10 %\n"
     ]
    }
   ],
   "source": [
    "categorical_percent_error(netA, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
